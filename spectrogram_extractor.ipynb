{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "spectrogram_extractor.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yootazi/spectrogram_extractor/blob/main/spectrogram_extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mq_SWmnGaM9"
      },
      "source": [
        "# **Spectrogram Extractor**\n",
        "# Extracting Spectrograms from an Audio Dataset located in Google Drive\n",
        "\n",
        "---\n",
        "\n",
        " by Yalda Zamani, 2021\n",
        "> Website: [www.yaldazamani.com](https://www.yaldazamani.com)\n",
        "\n",
        "> Twitter: [@yootazi](https://twitter.com/yootazi)\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "Currently it can be extract spectrograms from any dataset of .wav audio files at 44.1khz Sample Rate and 16bit bitdepth.\n",
        "\n",
        "> Credits:\n",
        "* coded following 'The Sound of AI' Youtube tutorial series by Valerio Velardo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi0K0g_fFa9A"
      },
      "source": [
        "Create a folder in your Google Drive called ai_music_projects. Create another folder within ai_music_projects called Spectrogram_Extractor. Create two empty folder 'audio' and 'spectrograms' within Spectrogram_Extractor to store your audio files and retrieve spectrograms.\n",
        "\n",
        "Make sure the path pointing to your folder look like these:\n",
        "\n",
        "'/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/audio'\n",
        "'/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/spectrograms'\n",
        "\n",
        "\n",
        "Move your audio files into the 'audio' folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "L391WnsV-pTQ"
      },
      "source": [
        "#@title **Importing Libraries**\n",
        "\n",
        "from PIL import Image\n",
        "import os                          # to load audiofiles\n",
        "import librosa                     \n",
        "import librosa.display             # for visualisation of spectrograms\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt    # plotting spectrograms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "R_ErcbJU-qiU"
      },
      "source": [
        "#@title **Mounting Google Drive**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OvNgWQ5n-pTV"
      },
      "source": [
        "#@title **Loading Audio Files from Google Drive**\n",
        "\n",
        "#writing a code to load all the file in the audio directory in file_x variables\n",
        "\n",
        "scale_file = \"/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/audio/scale.wav\"\n",
        "debussy_file = \"/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/audio/debussy.wav\"\n",
        "redhot_file = \"/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/audio/redhot.wav\"\n",
        "duke_file = \"/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/audio/duke.wav\"\n",
        "\n",
        "#writing a code to listen all the file in the audio directory in file_x variables\n",
        "\n",
        "ipd.Audio(scale_file) \n",
        "scale, sr = librosa.load(scale_file)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "5jXHvUCr-pTa"
      },
      "source": [
        "#@title **Extracting Short-Time Fourier Transform**\n",
        "\n",
        "FRAME_SIZE = 2048\n",
        "HOP_SIZE = 512\n",
        "\n",
        "S_scale = librosa.stft(scale, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
        "S_scale.shape\n",
        "type(S_scale[0][0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6q1VRT9Z-pTd"
      },
      "source": [
        "#@title **Calculating / Visualizing the Spectrogram**\n",
        "\n",
        "Y_scale = np.abs(S_scale) ** 2\n",
        "Y_scale.shape\n",
        "type(Y_scale[0][0])\n",
        "\n",
        "def plot_spectrogram(Y, sr, hop_length, y_axis=\"linear\"):\n",
        "    plt.figure(figsize=(25, 10))\n",
        "    librosa.display.specshow(Y, \n",
        "                             sr=sr, \n",
        "                             hop_length=hop_length, \n",
        "                             x_axis=\"time\", \n",
        "                             y_axis=y_axis)\n",
        "    plt.colorbar(format=\"%+2.f\")\n",
        "\n",
        "Y_log_scale = librosa.power_to_db(Y_scale)\n",
        "plot_spectrogram(Y_log_scale, sr, HOP_SIZE)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "b7DPR6Ld-pTe"
      },
      "source": [
        "#@title **Log-Frequency Spectrogram**\n",
        "\n",
        "plot_spectrogram(Y_log_scale, sr, HOP_SIZE, y_axis=\"log\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Ej7KCfo2-pTe"
      },
      "source": [
        "#@title **Visualising Songs From Different Files**\n",
        "\n",
        "S_debussy = librosa.stft(debussy, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
        "S_redhot = librosa.stft(redhot, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
        "S_duke = librosa.stft(duke, n_fft=FRAME_SIZE, hop_length=HOP_SIZE)\n",
        "\n",
        "\n",
        "Y_debussy = librosa.power_to_db(np.abs(S_debussy) ** 2)\n",
        "Y_redhot = librosa.power_to_db(np.abs(S_redhot) ** 2)\n",
        "Y_duke = librosa.power_to_db(np.abs(S_duke) ** 2)\n",
        "\n",
        "plot_spectrogram(Y_debussy, sr, HOP_SIZE, y_axis=\"log\")\n",
        "plot_spectrogram(Y_redhot, sr, HOP_SIZE, y_axis=\"log\")\n",
        "plot_spectrogram(Y_duke, sr, HOP_SIZE, y_axis=\"log\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BRBnvqcTEboX"
      },
      "source": [
        "#@title **Creating Spectrograms from All the Audio Files Located in 'audio' Folder**\n",
        "\n",
        "\"\"\"\n",
        "1- load a file\n",
        "2- pad the signal (if necessary)\n",
        "3- extracting log spectrogram from signal\n",
        "4- normalise spectrogram\n",
        "5- save the normalised spectrogram\n",
        "PreprocessingPipeline\n",
        "\"\"\"\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Loader:\n",
        "    \"\"\"Loader is responsible for loading an audio file.\"\"\"\n",
        "\n",
        "    def __init__(self, sample_rate, duration, mono):                        # constructor / in MIR audio can be analized when they are mono\n",
        "        self.sample_rate = sample_rate\n",
        "        self.duration = duration\n",
        "        self.mono = mono\n",
        "\n",
        "    def load(self, file_path):\n",
        "        signal = librosa.load(file_path,                                    # librosa.load returns 2 things: the signal and the sample rate\n",
        "                              sr=self.sample_rate,\n",
        "                              duration=self.duration,\n",
        "                              mono=self.mono)[0]                            # we take just the first index which is the signal (don'T need the sample rate)\n",
        "        return signal\n",
        "\n",
        "\n",
        "class Padder:\n",
        "    \"\"\"Padder is responsible to apply padding to an array.\"\"\"\n",
        "\n",
        "    def __init__(self, mode=\"constant\"):                                    # creating a constructor\n",
        "        self.mode = mode\n",
        "\n",
        "    def left_pad(self, array, num_missing_items):                           # missing items to prepend (add to the beginning of the array) / 0 items to append (add to the end of the array)\n",
        "        padded_array = np.pad(array,\n",
        "                              (num_missing_items, 0),\n",
        "                              mode=self.mode)\n",
        "        return padded_array\n",
        "\n",
        "    def right_pad(self, array, num_missing_items):                          # 0 items to prepend (add to the beginning of the array) / missing items to append (add to the end of the array)\n",
        "        padded_array = np.pad(array,\n",
        "                              (0, num_missing_items),\n",
        "                              mode=self.mode)\n",
        "        return padded_array\n",
        "\n",
        "\n",
        "class LogSpectrogramExtractor:\n",
        "    \"\"\"LogSpectrogramExtractor extracts log spectrograms (in dB) from a\n",
        "    time-series signal.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, frame_size, hop_length):\n",
        "        self.frame_size = frame_size\n",
        "        self.hop_length = hop_length\n",
        "\n",
        "    def extract(self, signal):\n",
        "        stft = librosa.stft(signal,                                          # extracting short time furier transport (stft)   (1 + frame_size / 2, num_frames)   1024 -> 513 (-1) -> 512\n",
        "                            n_fft=self.frame_size,\n",
        "                            hop_length=self.hop_length)[:-1]\n",
        "        spectrogram = np.abs(stft)\n",
        "        log_spectrogram = librosa.amplitude_to_db(spectrogram)\n",
        "        return log_spectrogram\n",
        "\n",
        "\n",
        "class MinMaxNormaliser:                                                      # we take the array and squish it into a normalized range between 1 and 0 (min -> 0 / max ->1)\n",
        "    \"\"\"MinMaxNormaliser applies min max normalisation to an array.\"\"\"\n",
        "\n",
        "    def __init__(self, min_val, max_val):\n",
        "        self.min = min_val\n",
        "        self.max = max_val\n",
        "\n",
        "    def normalise(self, array):\n",
        "        norm_array = (array - array.min()) / (array.max() - array.min())     # -> 0 / 1\n",
        "        norm_array = norm_array * (self.max - self.min) + self.min           # adding another range\n",
        "        return norm_array\n",
        "\n",
        "    def denormalise(self, norm_array, original_min, original_max):           # inverting the above expression\n",
        "        array = (norm_array - self.min) / (self.max - self.min)\n",
        "        array = array * (original_max - original_min) + original_min\n",
        "        return array\n",
        "\n",
        "\n",
        "class Saver:\n",
        "    \"\"\"saver is responsible to save features, and the min max values.\"\"\"\n",
        "\n",
        "    def __init__(self, feature_save_dir, min_max_values_save_dir):\n",
        "        self.feature_save_dir = feature_save_dir\n",
        "        self.min_max_values_save_dir = min_max_values_save_dir\n",
        "\n",
        "    def save_feature(self, feature, file_path):\n",
        "        save_path = self._generate_save_path(file_path)\n",
        "        np.save(save_path, feature)\n",
        "        return save_path                   # was added\n",
        "\n",
        "    def save_min_max_values(self, min_max_values):                                # we need to store the min max values for all the log spectrograms to reuse that for the reconstructing the signals and regenerating it\n",
        "        save_path = os.path.join(self.min_max_values_save_dir,\n",
        "                                 \"min_max_values.pkl\")\n",
        "        self._save(min_max_values, save_path)\n",
        "\n",
        "    @staticmethod\n",
        "    def _save(data, save_path):\n",
        "        with open(save_path, \"wb\") as f:\n",
        "            pickle.dump(data, f)\n",
        "\n",
        "    def _generate_save_path(self, file_path):\n",
        "        file_name = os.path.split(file_path)[1]\n",
        "        save_path = os.path.join(self.feature_save_dir, file_name + \".npy\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "class PreprocessingPipeline:                                                       # The higher level Class\n",
        "    \"\"\"PreprocessingPipeline processes audio files in a directory, applying\n",
        "    the following steps to each file:\n",
        "        1- load a file\n",
        "        2- pad the signal (if necessary)\n",
        "        3- extracting log spectrogram from signal\n",
        "        4- normalise spectrogram\n",
        "        5- save the normalised spectrogram\n",
        "    Storing the min max values for all the log spectrograms.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.padder = None\n",
        "        self.extractor = None                                                      # general extractor (logSpectrogramExtractor included)\n",
        "        self.normaliser = None\n",
        "        self.saver = None\n",
        "        self.min_max_values = {}                                                   # we need to store the min max values for all the log spectrograms to reuse that for the reconstructing the signals and regenerating it\n",
        "        self._loader = None\n",
        "        self._num_expected_samples = None\n",
        "\n",
        "    @property\n",
        "    def loader(self):\n",
        "        return self._loader\n",
        "\n",
        "    @loader.setter\n",
        "    def loader(self, loader):\n",
        "        self._loader = loader\n",
        "        self._num_expected_samples = int(loader.sample_rate * loader.duration)\n",
        "\n",
        "    def process(self, audio_files_dir):                                            # path to directory in which all audio files are stored\n",
        "        for root, _, files in os.walk(audio_files_dir):                            # lopping through all the files\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                self._process_file(file_path)\n",
        "                print(f\"Processed file {file_path}\")\n",
        "        self.saver.save_min_max_values(self.min_max_values)\n",
        "\n",
        "    def _process_file(self, file_path):\n",
        "        signal = self.loader.load(file_path)\n",
        "        if self._is_padding_necessary(signal):\n",
        "            signal = self._apply_padding(signal)\n",
        "        feature = self.extractor.extract(signal)\n",
        "        norm_feature = self.normaliser.normalise(feature)\n",
        "        save_path = self.saver.save_feature(norm_feature, file_path)\n",
        "        self._store_min_max_value(save_path, feature.min(), feature.max())\n",
        "\n",
        "    def _is_padding_necessary(self, signal):\n",
        "        if len(signal) < self._num_expected_samples:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def _apply_padding(self, signal):\n",
        "        num_missing_samples = self._num_expected_samples - len(signal)\n",
        "        padded_signal = self.padder.right_pad(signal, num_missing_samples)\n",
        "        return padded_signal\n",
        "\n",
        "    def _store_min_max_value(self, save_path, min_val, max_val):\n",
        "        self.min_max_values[save_path] = {\n",
        "            \"min\": min_val,\n",
        "            \"max\": max_val\n",
        "        }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    FRAME_SIZE = 512\n",
        "    HOP_LENGTH = 256\n",
        "    DURATION = 0.74  # in seconds\n",
        "    SAMPLE_RATE = 22050\n",
        "    MONO = True\n",
        "\n",
        "    SPECTROGRAMS_SAVE_DIR = '/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/spectrograms'\n",
        "    MIN_MAX_VALUES_SAVE_DIR = '/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/'\n",
        "    FILES_DIR = '/content/gdrive/MyDrive/ai_music_projects/Spectrogram_Extractor/audio/'\n",
        "\n",
        "    # instantiate all objects\n",
        "    loader = Loader(SAMPLE_RATE, DURATION, MONO)\n",
        "    padder = Padder()\n",
        "    log_spectrogram_extractor = LogSpectrogramExtractor(FRAME_SIZE, HOP_LENGTH)\n",
        "    min_max_normaliser = MinMaxNormaliser(0, 1)\n",
        "    saver = Saver(SPECTROGRAMS_SAVE_DIR, MIN_MAX_VALUES_SAVE_DIR)\n",
        "\n",
        "    preprocessing_pipeline = PreprocessingPipeline()\n",
        "    preprocessing_pipeline.loader = loader\n",
        "    preprocessing_pipeline.padder = padder\n",
        "    preprocessing_pipeline.extractor = log_spectrogram_extractor\n",
        "    preprocessing_pipeline.normaliser = min_max_normaliser\n",
        "    preprocessing_pipeline.saver = saver\n",
        "\n",
        "    preprocessing_pipeline.process(FILES_DIR)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "i4wJzNYMtkXR"
      },
      "source": [
        "#@title **saving image files of spectrograms**\n",
        "\n",
        "# saving image files of spectrograms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "\n",
        "\n",
        "filename = librosa.util.example_audio_file()\n",
        "y, sr = librosa.load(filename)\n",
        "y = y[:100000] # shorten audio a bit for speed\n",
        "\n",
        "window_size = 1024\n",
        "window = np.hanning(window_size)\n",
        "stft  = librosa.core.spectrum.stft(y, n_fft=window_size, hop_length=512, window=window)\n",
        "out = 2 * np.abs(stft) / np.sum(window)\n",
        "\n",
        "# For plotting headlessly\n",
        "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
        "\n",
        "fig = plt.Figure()\n",
        "canvas = FigureCanvas(fig)\n",
        "ax = fig.add_subplot(111)\n",
        "p = librosa.display.specshow(librosa.amplitude_to_db(out, ref=np.max), ax=ax, y_axis='log', x_axis='time')\n",
        "fig.savefig('spec.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}